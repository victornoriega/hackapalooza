{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller de an치lisis de sentimientos\n",
    "\n",
    "## Parte 1: Cargaremos las clases necesarias para poder trabajar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "import re\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn import metrics\n",
    "import random\n",
    "np.random.seed(42069)\n",
    "random.seed(69420)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Cargamos los datos de entrenamiento y pruebas en formatos que nos pueda entender SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tama침o del conjunto de datos: 1056.\n",
      "Primer ejemplo:\n",
      "Y NO EXISTE, no por un megaproyecto de alg칰n aeropuerto hijoeputa que vino a promover un ecocidio en la \"rica y verde zona del actual Texcoco\", sino que todo comenz칩 all치 por la 칠poca prehisp치nica, cuando los primeros chilangos tuvieron la muy rara idea de construir Tenochtitlan\n",
      "\n",
      "Tama침o de etiquetas 1056\n",
      "Primer etiqueta: 0\n",
      "\n",
      "Tama침o de pruebas: 237.\n",
      "Primer ejemplo:\n",
      "#CienciaUNAM El suelo de Texcoco no s칩lo es el menos apto, es el peor suelo en el que podr칤an construir un aeropuerto; una obra de este tipo requiere un suelo m치s s칩lido,  firme y esta 치rea es demasiado inestable para una edificaci칩n de esa magnitud:\n",
      "\n",
      "https://t.co/rjM4HR4zll https://t.co/ayW95wqcfN\n",
      "\n",
      "Tama침o de etiquetas 237\n",
      "Primer etiqueta: 1\n"
     ]
    }
   ],
   "source": [
    "with open(\"CLASIFICADOS.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    # Creando una lista o arreglo de tuits\n",
    "    x_train = re.split('\\nGolden label: -*[01]\\n', f.read())\n",
    "    print(\"Tama침o del conjunto de datos: {}.\\nPrimer ejemplo:\\n{}\".format(len(x_train), x_train[0]))\n",
    "    f.seek(0)\n",
    "    \n",
    "    # Creando una lista o arreglo de las etiquetas que corresponden a cada tuit\n",
    "    y_train = re.findall('-*[01]', ''.join(re.findall('Golden label: -*[01]', f.read())))\n",
    "    print(\"\\nTama침o de etiquetas {}\\nPrimer etiqueta: {}\".format(len(y_train), y_train[0]))\n",
    "with open(\"pruebas.txt\", 'r', encoding=\"utf-8\") as f:\n",
    "    x_test = re.split('\\nGolden label: -*[01]\\n', f.read())\n",
    "    print(\"\\nTama침o de pruebas: {}.\\nPrimer ejemplo:\\n{}\".format(len(x_test), x_test[0]))\n",
    "    f.seek(0)\n",
    "    y_test = re.findall('-*[01]', ''.join(re.findall('Golden label: -*[01]', f.read())))\n",
    "    print(\"\\nTama침o de etiquetas {}\\nPrimer etiqueta: {}\".format(len(y_test), y_test[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Representaci칩n n칰merica de los tuits: tokenizadores y otros par치metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pierde': 0.914, 'al': 0.911, '|': 0.907, '!': 0.736, 'gana': 0.9, 'del': 0.889, 'agua': 0.757, '...': 0.831, '-': 0.814, 'aqu칤': 0.751, 'inversionistas': 0.79, '4': 0.786, 'tres': 0.775, 'sin': 0.765, 'voto': 0.729, 'estaba': 0.755, '游땍': 0.717, 'construido': 0.738, 'peso': 0.729, 'cancelaci칩n': 0.728, '$': 0.724, '\"': 0.71, 'c칩mo': 0.72, '游뱂': 0.719, 'unam': 0.717, 'algunos': 0.709, 'voy': 0.708, 'tema': 0.707, 'haga': 0.706, 'todos': 0.698, 'cancela': 0.696}\n",
      "['lecho', 'siga', 'demostrar', 'dan', 'recorrer', 'cent칤metros', 'sudado', 'apoyar', 'conoce', 'conjunta', 'ganadora', 'fox', 'buena', 'acuiferos', 'https://t.co/5m8vnrkhfa']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(x_train)\n",
    "print(sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1]))\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.85, min_df=8)\n",
    "tfidf = vectorizer.fit_transform(x_train)\n",
    "sorted(vectorizer.vocabulary_.items(), key=lambda x: x[1])\n",
    "\"\"\"\n",
    "\n",
    "tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True)\n",
    "vectorizer = TfidfVectorizer(max_df=0.85, min_df=8, tokenizer=tokenizer.tokenize)\n",
    "tfidf = vectorizer.fit_transform(x_train)\n",
    "\n",
    "tfidf_test = vectorizer.transform(x_test)\n",
    "\n",
    "def sort_coo(coo_matrix):\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    " \n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    " \n",
    "    #create a tuples of feature,score\n",
    "    #results = zip(feature_vals,score_vals)\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "sorted_items = sort_coo(tfidf.tocoo())\n",
    "keywords = extract_topn_from_vector(vocab,sorted_items, 50)\n",
    "print(keywords)\n",
    "print(random.sample(vectorizer.stop_words_, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Predicci칩n de nuevos tuits utilizando algoritmos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.729957805907173, 0.7050753595647962, 0.6628998000999501, 0.7299578059071729]\n"
     ]
    }
   ],
   "source": [
    "rl = LR(solver='liblinear', multi_class='ovr')\n",
    "rl.fit(tfidf, y_train)\n",
    "\n",
    "pred = rl.predict(tfidf_test)\n",
    "\n",
    "score = [metrics.accuracy_score(y_test, pred), metrics.precision_score(y_test, pred, average='macro'), \n",
    "         metrics.recall_score(y_test, pred, average='macro'), metrics.f1_score(y_test, pred, average='micro')]\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 춰Felicidades! Acabas de completar tu primer an치lisis de sentimientos. Un clasificador con alrededor del 70% de 칠xito es excelente para los problemas de Procesamiento de Lenguaje Natural de hoy en d칤a, sobre todo en espa침ol.\n",
    "\n",
    "## Piensa que has sacado 70 en un examen, en el que el profe que da esa materia a lo mucho llega a dar 90's, pero solo a esos que tienen 8 GPU's y que solo se dedican a pasar esa materia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
